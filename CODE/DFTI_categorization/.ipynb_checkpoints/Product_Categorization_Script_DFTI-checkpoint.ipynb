{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "overhead-spotlight",
   "metadata": {},
   "source": [
    "# Direct Frequency Topic Identification (DFTI)\n",
    "\n",
    "One of the challenges with using LDA is that it is an unsupervised algorithm.  As a result, like PCA, the clusters that it discovers may or may not align with desired goals of data scientists.  As an example consider the following text for review:\n",
    "\n",
    "\"My dog really likes this cat food made from fish products.  Most dog food he has tried hasn't gone over well with him at all.  But this product is really outstanding.\"\n",
    "\n",
    "In the above scenario, this text might be classified as either dog, cat or fish.  It could also be classified as food or product depending on how the LDA system is configured.\n",
    "\n",
    "As a way to get around this problem, a different approach could be used.  If, instead of starting with the review text, what if we started with buckets.  Such as the following:\n",
    "\n",
    "dog\n",
    "cat\n",
    "fish\n",
    "bird\n",
    "rabbit\n",
    "turtle\n",
    "snake\n",
    "rat\n",
    "mouse\n",
    "hamster\n",
    "gerbil\n",
    "reptile\n",
    "horse\n",
    "other\n",
    "\n",
    "Now, we might be able to create our own guess at \"categorizing\" the reviews by counting the number of times these words appear in a document, and then using that information to drive the probability of category.  For example\n",
    "\n",
    "| ASIN | dog | cat | fish | etc | \n",
    "|---|---|---|---|---|\n",
    "| 123456778 | 2 | 1 | 1 | ... |\n",
    "\n",
    "The following code will attempt to do this for the products in the data set.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "solar-export",
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "no such table: reviews",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-55e735ee53dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mcur\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCONN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcursor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SELECT asin from reviews\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0masins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetchall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Number of reviews: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOperationalError\u001b[0m: no such table: reviews"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "CONN = sqlite3.connect('pets.db')\n",
    "buckets = ['dog','cat','fish','bird','amphibians and reptiles','rabbits and rodents','farm animals']\n",
    "\n",
    "words = {\n",
    "'dog' : ['dog', 'dogs', 'puppy', 'pup', 'puppies', 'paw', 'paws'],\n",
    "'cat' : ['cat', 'cats', 'kitten', 'kittens', 'feline', 'felines'],\n",
    "'fish' : ['goldfish', 'fish', 'fishes', 'koi', 'angelfish', 'catfish', 'guppies', 'freshwater', 'saltwater'],\n",
    "'bird' : ['parrot','parrots','beak', 'feather','beaks', 'feathers', 'bird', 'birds', 'canary', 'canaries','budgerigar','budgerigars','budgies', 'parakeets','cockatiel','cockatiels','cockatoo','cockatoos','macaw','macaws', 'dove','doves'],\n",
    "'rabbits and rodents' : ['rabbit', 'rabbits', 'bunny', 'bunnies', 'hare', 'hares','lop','rat','mouse','hamster','gerbil','rats','mice','hamsters','gerbils', 'rodents', 'rodent', 'guinea', 'ferret', 'hedgehog','ferrets', 'hedgehogs'],\n",
    "# 'turtle' : ['turtle', 'turtles', 'tortoise', 'tortoises', 'cooter', 'loggerhead','snapper', 'terrapin','leatherback'],\n",
    "# 'rodent' : ['rat','mouse','hamster','gerbil','rats','mice','hamsters','gerbils', 'rodents', 'rodent', 'guinea', 'ferret', 'hedgehog','ferrets', 'hedgehogs'],\n",
    "# 'rabbit' : ['rabbit', 'rabbits', 'bunny', 'bunnies', 'hare', 'hares','lop'],\n",
    "'farm animals': ['chicken','chicks','chickens', 'duck', 'ducks','goat', 'goats', 'bull','cow','bulls','cows','lamb','sheep', 'sheeps','horse','pony','horses','ponies', 'stud','mare','studs','mares'],\n",
    "'amphibians and reptiles':['turtle', 'turtles', 'tortoise', 'tortoises','tadpole', 'tadpoles', 'cooter', 'loggerhead','snapper', 'terrapin','leatherback', 'snake', 'snakes', 'gecko', 'geckos','lizard', 'lizards', 'frog', 'frogs', 'toad', 'toads', 'amphibian', 'amphibians', 'reptile', 'reptiles','snake','snakes', 'dragon', 'dragons']\n",
    "}\n",
    "\n",
    "# print(words)\n",
    "\n",
    "cur = CONN.cursor()\n",
    "\n",
    "cur.execute(\"SELECT asin from reviews\")\n",
    "asins = cur.fetchall()\n",
    "print(\"Number of reviews: {}\".format(len(asins)))\n",
    "\n",
    "cur.execute(\"SELECT DISTINCT asin from reviews\")\n",
    "counts=[]\n",
    "unique_asins = cur.fetchall()\n",
    "print(\"Unique asins found: {}\".format(len(unique_asins)))\n",
    "start=datetime.now()\n",
    "\n",
    "i=0\n",
    "\n",
    "product_description = get_title()\n",
    "\n",
    "for asin in unique_asins:\n",
    "    i=i+1\n",
    "    prog = i/len(unique_asins)*100\n",
    "    \n",
    "    if prog % 10 == 0:\n",
    "        print(\"{}%\".format(prog))\n",
    "    \n",
    "    sql = \"select review_text from reviews where asin = '{}'\".format(asin[0])\n",
    "    cur.execute(sql)\n",
    "    rec = [asin[0]]\n",
    "    full_text = \" \".join([x[0] for x in cur.fetchall()])\n",
    "    if (asin[0] in result_dict):\n",
    "        full_text = full_text + product_description[asin[0]]\n",
    "    for bucket in buckets:\n",
    "        cnt = sum(full_text.lower().count(x) for x in words[bucket])\n",
    "        rec.append(cnt)\n",
    "    counts.append(rec)\n",
    "       \n",
    "print(\"Compute time {}\".format(datetime.now()-start))\n",
    "            \n",
    "results_df = pd.DataFrame(counts)\n",
    "# display(results_df.head(20))\n",
    "\n",
    "def get_title():\n",
    "    cur.execute(\"SELECT asin, title, description from products\")\n",
    "    titles = cur.fetchall()\n",
    "    results_df = pd.DataFrame(titles)\n",
    "    results_df.columns = ['asin', 'title','description']\n",
    "    results_df[\"combined\"] = results_df[\"title\"] + results_df[\"description\"]\n",
    "    result_dict = dict(zip(results_df.asin, results_df.combined))\n",
    "    return result_dict\n",
    "\n",
    "def get_max_row(x):\n",
    "    vals = x.values[1:]\n",
    "    if max(vals)==0:\n",
    "        return -1\n",
    "    else:\n",
    "        return(np.argmax(vals))\n",
    "\n",
    "def get_topic(row, b):\n",
    "    x = row['topic_id']\n",
    "    if x==-1:\n",
    "        return \"other\"\n",
    "    else:\n",
    "        return b[x]\n",
    "        \n",
    "results_df['topic_id'] = results_df.apply(lambda row: get_max_row(row), axis=1)\n",
    "results_df['topic'] = results_df.apply(lambda row: get_topic(row, buckets), axis=1)\n",
    "\n",
    "results_df.rename(columns={0:'asin'}, inplace=True)\n",
    "results_df = results_df[['asin','topic_id','topic']]\n",
    "display(results_df.head(10))\n",
    "results_df.to_csv('category.csv', index=False)\n",
    "results_df.groupby('topic').count()\n",
    "\n",
    "# filtered = results_df.loc[results_df['topic'] == 'other']\n",
    "# display(filtered.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unnecessary-frontier",
   "metadata": {},
   "source": [
    "# Let's see how we did.  \n",
    "\n",
    "In this cell we will take a random sample of 10 rows from the dataset and see how our grouping compares to that of the product description\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trained-purpose",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_df = results_df.sample(n=20)\n",
    "\n",
    "def get_product(asin):\n",
    "    cur.execute(\"Select title from products where asin = '{}'\".format(asin))\n",
    "    product = cur.fetchall()\n",
    "    return product[0]\n",
    "\n",
    "# for idx, row in sample_df.iterrows():\n",
    "#     print(get_product(row['asin']))\n",
    "#     print(row['topic'])\n",
    "#     print(\"\\n\\n\")\n",
    "    \n",
    "def get_title():\n",
    "    cur.execute(\"SELECT asin, title, description from products LIMIT 10\")\n",
    "#     cur.execute(\"SELECT * from sqlite_master WHERE tbl_name = 'products' AND type = 'table'\")\n",
    "    titles = cur.fetchall()\n",
    "    results_df = pd.DataFrame(titles)\n",
    "    results_df.columns = ['asin', 'title','description']\n",
    "    results_df[\"combined\"] = results_df[\"title\"] + results_df[\"description\"]\n",
    "    result_dict = dict(zip(results_df.asin, results_df.combined))\n",
    "    return result_dict\n",
    "    \n",
    "\n",
    "result_dict = get_title()\n",
    "counts=[]\n",
    "i=0\n",
    "\n",
    "for asin in unique_asins:\n",
    "    i=i+1\n",
    "    prog = i/len(unique_asins)*100\n",
    "    rec = [asin[0]]\n",
    "    if (asin[0] in result_dict):\n",
    "        full_text = result_dict[asin[0]]\n",
    "        for bucket in buckets:\n",
    "            cnt = sum(full_text.lower().count(x) for x in words[bucket])\n",
    "            rec.append(cnt)\n",
    "    else:\n",
    "        for bucket in buckets:\n",
    "            cnt = 0\n",
    "            rec.append(cnt)\n",
    "        \n",
    "    counts.append(rec)\n",
    "    \n",
    "results_df = pd.DataFrame(counts)\n",
    "display(results_df.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breathing-crown",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
